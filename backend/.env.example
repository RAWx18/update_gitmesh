# ========================
# PYTHON BACKEND ENVIRONMENT CONFIGURATION
# ========================

# ========================
# ESSENTIAL API KEYS & SECRETS
# ========================
# OpenAI API Key (optional - for OpenAI models)
OPENAI_API_KEY=your_openai_api_key_here

# Google Gemini API Key (for Gemini models)
GEMINI_API_KEY=your_gemini_api_key_here

# Jina AI API Key (optional - for Jina embeddings)
JINA_API_KEY=your_jina_api_key_here

# ========================
# VECTOR DATABASE CONFIGURATION
# ========================
# Qdrant Mode: "online" or "local"
QDRANT_MODE=local

# Qdrant Online Configuration (when QDRANT_MODE=online)
QDRANT_URL_ONLINE=https://your-qdrant-cluster.cloud.qdrant.io:6333
QDRANT_API_KEY=your_qdrant_api_key_here

# Qdrant Local Configuration (when QDRANT_MODE=local)
# These are used when running Qdrant locally
QDRANT_URL=localhost
QDRANT_PORT=6333

# ========================
# CACHE & SESSION STORAGE
# ========================
# Redis Configuration
REDIS_URL=redis://localhost:6379
REDIS_DB=0
REDIS_PASSWORD=
REDIS_SSL=false
REDIS_MAX_CONNECTIONS=20
REDIS_CONNECTION_TIMEOUT=5
REDIS_SOCKET_TIMEOUT=5
REDIS_RETRY_ON_TIMEOUT=true

# ========================
# SECURITY CONFIGURATION
# ========================
# Secret key for JWT tokens and encryption (minimum 32 characters)
SECRET_KEY=your-super-secret-key-change-in-production-minimum-32-chars

# ========================
# OBSERVABILITY & LOGGING
# ========================
# Trace file for application tracing
TRACE_FILE=./traces.jsonl

# ========================
# AI PIPELINE SETTINGS
# ========================
# Document processing limits
AI_MAX_DOCUMENTS=1000
AI_BATCH_SIZE=32

# Model configurations
AI_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
AI_CHAT_MODEL=gemini-2.0-flash

# Web scraping settings
AI_MAX_PAGES=10
AI_MAX_DEPTH=2
AI_SCRAPER_TIMEOUT=30000

# Content formatting settings
AI_MIN_CONTENT_LENGTH=50
AI_MAX_CONTENT_LENGTH=100000
AI_REMOVE_HTML=true
AI_DETECT_LANGUAGE=true
AI_GENERATE_SUMMARY=true

# Collection name for vector storage
AI_COLLECTION_NAME=documents

# Search configuration
AI_USE_HYBRID_SEARCH=true
AI_KEYWORD_WEIGHT=0.3
AI_VECTOR_WEIGHT=0.7

# Prompt and context settings
AI_MAX_CONTEXT_LENGTH=4000
AI_MAX_SOURCES=5
AI_INCLUDE_CITATIONS=true
AI_INCLUDE_CONFIDENCE=true

# Response generation settings
AI_MAX_TOKENS=1000
AI_TEMPERATURE=0.7
AI_TOP_P=0.9
AI_TOP_K=40

# ========================
# CACHE TTL CONFIGURATION
# ========================
# File content cache TTLs (in seconds)
FILE_CONTENT_TTL=3600          # 1 hour
FILE_METADATA_TTL=7200         # 2 hours
GITHUB_API_TTL=1800           # 30 minutes

# Embedding cache TTLs (in seconds)
EMBEDDING_TTL=86400           # 24 hours
CHUNK_EMBEDDING_TTL=86400     # 24 hours
BATCH_EMBEDDING_TTL=86400     # 24 hours

# Query result cache TTLs (in seconds)
QUERY_RESULT_TTL=1800         # 30 minutes
SEMANTIC_QUERY_TTL=3600       # 1 hour
CONTEXT_CACHE_TTL=7200        # 2 hours

# Session cache TTLs (in seconds)
SESSION_TTL=3600              # 1 hour
SESSION_CONTEXT_TTL=7200      # 2 hours
USER_PREFERENCES_TTL=86400    # 24 hours

# ========================
# LOCAL CACHE CONFIGURATION
# ========================
LOCAL_CACHE_DIR=./cache
LOCAL_CACHE_MAX_SIZE=1073741824    # 1GB in bytes
LOCAL_CACHE_CLEANUP_INTERVAL=3600  # 1 hour

# ========================
# MEMORY CACHE CONFIGURATION
# ========================
MEMORY_CACHE_MAX_SIZE=1000    # Number of items
MEMORY_CACHE_TTL=300          # 5 minutes

# ========================
# COMPRESSION CONFIGURATION
# ========================
COMPRESSION_ENABLED=true
COMPRESSION_THRESHOLD=1048576  # 1MB in bytes
COMPRESSION_ALGORITHM=gzip     # Options: gzip, lz4, zstd

# ========================
# DEDUPLICATION CONFIGURATION
# ========================
DEDUPLICATION_ENABLED=true
SEMANTIC_SIMILARITY_THRESHOLD=0.95
HASH_DEDUPLICATION_ENABLED=true

# ========================
# CHUNKING CONFIGURATION
# ========================
DEFAULT_CHUNK_SIZE=1000
DEFAULT_CHUNK_OVERLAP=200
MAX_CHUNK_SIZE=2000
MIN_CHUNK_SIZE=100

# Language-specific chunking
PYTHON_CHUNK_SIZE=800
JAVASCRIPT_CHUNK_SIZE=1000
JAVA_CHUNK_SIZE=1200
MARKDOWN_CHUNK_SIZE=1500
CONFIG_CHUNK_SIZE=500

# ========================
# ERROR HANDLING CONFIGURATION
# ========================
MAX_RETRIES=3
RETRY_DELAY=1.0
CIRCUIT_BREAKER_THRESHOLD=5
CIRCUIT_BREAKER_TIMEOUT=60

# ========================
# MONITORING CONFIGURATION
# ========================
CACHE_METRICS_ENABLED=true
CACHE_METRICS_INTERVAL=300    # 5 minutes
CACHE_HEALTH_CHECK_INTERVAL=60 # 1 minute

# ========================
# SECURITY CONFIGURATION
# ========================
CACHE_ENCRYPTION_ENABLED=false
CACHE_ENCRYPTION_KEY=
CACHE_ACCESS_LOGGING=true

# ========================
# PERFORMANCE CONFIGURATION
# ========================
BACKGROUND_PROCESSING_ENABLED=true
PARALLEL_PROCESSING_WORKERS=4
BATCH_PROCESSING_SIZE=10
STREAMING_ENABLED=true

# ========================
# CONTEXT MANAGEMENT CONFIGURATION
# ========================
MAX_CONTEXT_FILES=50
MAX_CONTEXT_TOKENS=100000
CONTEXT_WINDOW_SIZE=10
CONTEXT_RELEVANCE_THRESHOLD=0.7

# ========================
# RATE LIMITING
# ========================
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# ========================
# EXTERNAL SERVICE INTEGRATION
# ========================
# Node.js backend URL (for integration with beetle_backend)
PYTHON_SERVER=http://localhost:8000

# ========================
# DEVELOPMENT SETTINGS
# ========================
# Set to true for development, false for production
DEBUG=true

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Environment: development, testing, production
ENVIRONMENT=development